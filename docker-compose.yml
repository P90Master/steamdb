# TODO: cluster name
# TODO: profiles
# TODO: healthcheck
# TODO: deploy
# TODO: volumes conf
# TODO: container names?
# TODO: depends conditions
# TODO: hostnames
# TODO: build
# TODO: restart
# TODO: worker deploy replicas
# TODO: defaults in environment
# TODO: commons environment variables (f.e. rabbitmq connection credentials)
# TODO: docker-compose.dev.yml
# TODO: solve port conflicts
# TODO: stages in Dockerfile
# TODO: security issues (root users, xpack.security, etc.)

services:

  # auth ############################################################

  auth:
    build:
      context: auth/
    container_name: auth
    volumes:
      - auth-static:/auth/static/admin
    environment:
      DEBUG: ${DEBUG}
      LOGGER_WRITE_IN_FILE: ${AUTH_LOGGER_WRITE_IN_FILE}
      LOGGER_LOG_FILES_PATH: ${AUTH_LOGGER_LOG_FILES_PATH}

      PORT: ${AUTH_PORT:-8001}
      WORKERS: ${AUTH_WORKERS}
      TIMEOUT_KEEP_ALIVE: ${AUTH_TIMEOUT_KEEP_ALIVE}
      LIMIT_CONCURRENCY: ${AUTH_LIMIT_CONCURRENCY}
      BACKLOG_SIZE: ${AUTH_BACKLOG_SIZE}

      SUPERUSER_USERNAME: ${AUTH_SUPERUSER_USERNAME}
      SUPERUSER_PASSWORD: ${AUTH_SUPERUSER_PASSWORD}
      ESSENTIAL_BACKEND_CLIENT_ID: ${ESSENTIAL_BACKEND_CLIENT_ID}
      ESSENTIAL_BACKEND_CLIENT_SECRET: ${ESSENTIAL_BACKEND_CLIENT_SECRET}
      ESSENTIAL_WORKER_CLIENT_ID: ${ESSENTIAL_WORKER_CLIENT_ID}
      ESSENTIAL_WORKER_CLIENT_SECRET: ${ESSENTIAL_WORKER_CLIENT_SECRET}

      DB_HOST: ${AUTH_DB_HOST}
      DB_PORT: ${AUTH_DB_PORT}
      DB_USER: ${AUTH_DB_USER}
      DB_PASSWORD: ${AUTH_DB_PASSWORD}
      DB_NAME: ${AUTH_DB_NAME}

      CELERY_NAME: ${AUTH_CELERY_NAME}
      CELERY_BROKER_HOST: ${AUTH_CELERY_BROKER_HOST}
      CELERY_BROKER_PORT: ${AUTH_CELERY_BROKER_PORT}
      CELERY_BROKER_PROTOCOL: ${AUTH_CELERY_BROKER_PROTOCOL}
      CELERY_TASK_TIME_LIMIT: ${AUTH_CELERY_TASK_TIME_LIMIT}
      CELERY_SCHEDULE_CLEAN_EXPIRED_TOKENS: ${AUTH_CELERY_SCHEDULE_CLEAN_EXPIRED_TOKENS}

      CACHE_PROTOCOL: ${AUTH_CACHE_PROTOCOL}
      CACHE_HOST: ${AUTH_CACHE_HOST}
      CACHE_PORT: ${AUTH_CACHE_PORT}
      CACHE_PASSWORD: ${AUTH_CACHE_PASSWORD}
      CACHE_TIMEOUT: ${AUTH_CACHE_TIMEOUT}
    restart: always
    depends_on:
      - auth-db
      - auth-cache
      - auth-task-broker
    # TODO: expose. Now for debug. From host only admin panel (http(s)://0.0.0.0:5000/admin) is accessible (through nginx proxy)
    ports:
      - "${AUTH_PORT:-8001}:8001"
    networks:
      - common
      - auth

  auth-db:
    # TODO: configure resources consumption
    image: postgres:16
    restart: always
    environment:
      POSTGRES_USER: ${AUTH_DB_USER}
      POSTGRES_PASSWORD: ${AUTH_DB_PASSWORD}
      POSTGRES_DB: ${AUTH_DB_NAME}
    expose:
      - "${AUTH_DB_PORT:-5432}"
    volumes:
      - auth-db-data:/var/lib/postgresql/data
    networks:
      - auth

  auth-cache:
    image: "redis:alpine"
    restart: always
    command: redis-server --requirepass ${AUTH_CACHE_PASSWORD}
    expose:
      - "${AUTH_CACHE_PORT:-6379}"
    networks:
      - auth

  auth-task-broker:
    image: redis:latest
    expose:
      - "6379"
    networks:
      - auth

  # main db ##############################################################

  db:
    # TODO: configure resources consumption
    image: mongo
    restart: always
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
    volumes:
      - mongo_data:/data/db
    expose:
      - "27017"
    networks:
      - backend

  db-gui:
    # TODO: docker-compose.dev.yml
    image: mongo-express
    restart: always
    depends_on:
      - db
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_USER}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_PASSWORD}
      ME_CONFIG_MONGODB_URL: 'mongodb://${MONGO_USER}:${MONGO_PASSWORD}@${MONGO_HOST}:${MONGO_PORT}/'
      ME_CONFIG_BASICAUTH: false
    ports:
      - "8081:8081"
    networks:
      - common
      - backend

  # fulltext search ##############################################################

  ftsearch-index:
    image: elasticsearch:8.4.3
    restart: always
    expose:
      - "${FTSEARCH_ELASTICSEARCH_PORT:-9200}"
      - "9300"
    environment:
      # TODO: cleaning
      - cluster.name=ftsearch-index
      - discovery.type=single-node
      - ELASTIC_PASSWORD=$FTSEARCH_ELASTICSEARCH_PASSWORD
      - xpack.security.enabled=false  # TODO: xpack.security.enabled
      # TODO: xpack.security.http.ssl.certificate
      - xpack.license.self_generated.type=basic
      - bootstrap.memory_lock=true
      - "ES_JAVA_OPTS=-Xms${FTSEARCH_ELASTICSEARCH_MEMORY:-512m} -Xmx${FTSEARCH_ELASTICSEARCH_MEMORY:-512m}"
    volumes:
      - ftsearch-index-data:/usr/share/elasticsearch/data
    networks:
      - backend

  ftsearch-index-gui:
    image: docker.elastic.co/kibana/kibana:8.4.3
    environment:
      ELASTICSEARCH_HOSTS: "http://${FTSEARCH_ELASTICSEARCH_HOST:-ftsearch-index}:${FTSEARCH_ELASTICSEARCH_PORT:-9200}"
      ELASTICSEARCH_USERNAME: ${FTSEARCH_ELASTICSEARCH_USER}
      ELASTICSEARCH_PASSWORD: ${FTSEARCH_ELASTICSEARCH_PASSWORD}
    ports:
      - "5602:5601"
    depends_on:
      - ftsearch-index
    networks:
      - backend

  ftsearch-etl-state-storage:
    image: redis:latest
    command: redis-server --requirepass ${FTSEARCH_STATE_STORAGE_PASSWORD}
    expose:
      - "${FTSEARCH_STATE_STORAGE_PORT:-6379}"
    volumes:
      - ftsearch-etl-state-storage-data:/data
    networks:
      - backend

  ftsearch-etl:
    build:
      context: etl/
    container_name: ftsearch-etl
    environment:
      DEBUG: ${DEBUG}

      MONGO_HOST: ${MONGO_HOST}
      MONGO_PORT: ${MONGO_PORT}
      MONGO_USER: ${MONGO_USER}
      MONGO_PASSWORD: ${MONGO_PASSWORD}
      MONGO_DB: ${MONGO_DB}

      STATE_STORAGE_PROTOCOL: ${FTSEARCH_STATE_STORAGE_PROTOCOL}
      STATE_STORAGE_HOST: ${FTSEARCH_STATE_STORAGE_HOST}
      STATE_STORAGE_PORT: ${FTSEARCH_STATE_STORAGE_PORT}
      STATE_STORAGE_PASSWORD: ${FTSEARCH_STATE_STORAGE_PASSWORD}

      ELASTICSEARCH_HOST: ${FTSEARCH_ELASTICSEARCH_HOST}
      ELASTICSEARCH_PORT: ${FTSEARCH_ELASTICSEARCH_PORT}
      ELASTICSEARCH_USER: ${FTSEARCH_ELASTICSEARCH_USER}
      ELASTICSEARCH_PASSWORD: ${FTSEARCH_ELASTICSEARCH_PASSWORD}
      ELASTICSEARCH_INDEX: ${FTSEARCH_ELASTICSEARCH_INDEX}
      BATCH_SIZE: ${FTSEARCH_ETL_BATCH_SIZE}
    deploy:
      restart_policy:
        condition: always
        delay: 5s
        window: 120s
    depends_on:
      - ftsearch-index
      - ftsearch-etl-state-storage
      - db
    networks:
      - backend

  # backend #########################################################

  backend:
    build:
      context: backend/
    container_name: backend
    environment:
      DEBUG: ${DEBUG}
      API_VERSION: ${BACKEND_API_VERSION}
      DEFAULT_COUNTRY_CODE: ${DEFAULT_COUNTRY_CODE}
      LOGGER_WRITE_IN_FILE: ${BACKEND_LOGGER_WRITE_IN_FILE}
      LOGGER_LOG_FILES_PATH: ${BACKEND_LOGGER_LOG_FILES_PATH}

      PORT: ${BACKEND_PORT:-8000}
      WORKERS: ${BACKEND_WORKERS}
      TIMEOUT_KEEP_ALIVE: ${BACKEND_TIMEOUT_KEEP_ALIVE}
      LIMIT_CONCURRENCY: ${BACKEND_LIMIT_CONCURRENCY}
      BACKLOG_SIZE: ${BACKEND_BACKLOG_SIZE}

      OAUTH2_SERVER_HOST: ${OAUTH2_SERVER_HOST}
      OAUTH2_SERVER_PORT: ${OAUTH2_SERVER_PORT}
      OAUTH2_SERVER_PROTOCOL: ${OAUTH2_SERVER_PROTOCOL}
      ESSENTIAL_BACKEND_CLIENT_ID: ${ESSENTIAL_BACKEND_CLIENT_ID}
      ESSENTIAL_BACKEND_CLIENT_SECRET: ${ESSENTIAL_BACKEND_CLIENT_SECRET}

      MONGO_HOST: ${MONGO_HOST}
      MONGO_PORT: ${MONGO_PORT}
      MONGO_USER: ${MONGO_USER}
      MONGO_PASSWORD: ${MONGO_PASSWORD}
      MONGO_DB: ${MONGO_DB}

      CACHE_PROTOCOL: ${BACKEND_CACHE_PROTOCOL}
      CACHE_HOST: ${BACKEND_CACHE_HOST}
      CACHE_PORT: ${BACKEND_CACHE_PORT}
      CACHE_TIMEOUT: ${BACKEND_CACHE_TIMEOUT}

      ELASTICSEARCH_HOST: ${FTSEARCH_ELASTICSEARCH_HOST}
      ELASTICSEARCH_PORT: ${FTSEARCH_ELASTICSEARCH_PORT}
      ELASTICSEARCH_USER: ${FTSEARCH_ELASTICSEARCH_USER}
      ELASTICSEARCH_PASSWORD: ${FTSEARCH_ELASTICSEARCH_PASSWORD}
      ELASTICSEARCH_INDEX: ${FTSEARCH_ELASTICSEARCH_INDEX}

      ORCHESTRATOR_PROTOCOL: ${ORCHESTRATOR_PROTOCOL}
      ORCHESTRATOR_HOST: ${ORCHESTRATOR_HOST}
      ORCHESTRATOR_PORT: ${ORCHESTRATOR_PORT}
      ORCHESTRATOR_API_VERSION: ${ORCHESTRATOR_API_VERSION}
    restart: always
    depends_on:
      - db
      - backend-cache
    # TODO: expose. Now for debug. From host accessible at http(s)://0.0.0.0:80 (through nginx proxy)
    ports:
      - "${BACKEND_PORT:-8000}:8000"
    networks:
      - backend
      - common

  backend-cache:
    image: "redis:alpine"
    restart: always
    expose:
      - "${BACKEND_CACHE_PORT:-6379}"
    networks:
      - backend

  # orchestrator & workers cluster ###################################

  orchestrator-worker-broker:
    image: rabbitmq:3-management
    environment:
      RABBITMQ_DEFAULT_USER: ${RABBITMQ_USER}
      RABBITMQ_DEFAULT_PASS: ${RABBITMQ_PASSWORD}
    volumes:
      - ./orchestrator-worker-broker.conf:/etc/rabbitmq/rabbitmq.conf
      - orchestrator-worker-broker-data:/var/lib/rabbitmq
    expose:
      - "5672"
      - "15672"  # with expose lose management UI port
    networks:
      - orchestrator
      - worker

  # orchestrator #####################################################

  orchestrator:
    build:
      context: /orchestrator
    container_name: orchestrator
    environment:
      DEBUG: ${DEBUG}
      BATCH_SIZE_OF_UPDATING_STEAM_APPS: ${ORCHESTRATOR_BATCH_SIZE_OF_UPDATING_STEAM_APPS}
      DEFAULT_COUNTRY_CODE: ${DEFAULT_COUNTRY_CODE}
      API_VERSION: ${ORCHESTRATOR_API_VERSION}
      OAUTH2_SERVER_HOST: ${OAUTH2_SERVER_HOST}
      OAUTH2_SERVER_PORT: ${OAUTH2_SERVER_PORT}
      OAUTH2_SERVER_PROTOCOL: ${OAUTH2_SERVER_PROTOCOL}

      LOGGER_WRITE_IN_FILE: ${ORCHESTRATOR_LOGGER_WRITE_IN_FILE}
      LOGGER_LOG_FILES_PATH: ${ORCHESTRATOR_LOGGER_LOG_FILES_PATH}

      STEAM_APP_LIST_URL: ${STEAM_APP_LIST_URL}
      STEAM_APP_DETAIL_URL: ${STEAM_APP_DETAIL_URL}

      BACKEND_PROTOCOL: ${BACKEND_PROTOCOL}
      BACKEND_HOST: ${BACKEND_HOST}
      BACKEND_PORT: ${BACKEND_PORT}
      BACKEND_API_VERSION: ${BACKEND_API_VERSION}

      RABBITMQ_HOST: ${RABBITMQ_HOST}
      RABBITMQ_PORT: ${RABBITMQ_PORT}
      RABBITMQ_USER: ${RABBITMQ_USER}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      RABBITMQ_INCOME_QUERY: ${ORCHESTRATOR_RABBITMQ_INCOME_QUERY}
      RABBITMQ_OUTCOME_QUERY: ${ORCHESTRATOR_RABBITMQ_OUTCOME_QUERY}
      RABBITMQ_CONNECTION_ATTEMPTS: ${RABBITMQ_CONNECTION_ATTEMPTS}
      RABBITMQ_CONNECTION_RETRY_DELAY: ${RABBITMQ_CONNECTION_RETRY_DELAY}
      RABBITMQ_HEARTBEATS_MAX_DELAY: ${RABBITMQ_HEARTBEATS_MAX_DELAY}

      CELERY_NAME: ${ORCHESTRATOR_CELERY_NAME}
      CELERY_BROKER_HOST: ${ORCHESTRATOR_CELERY_BROKER_HOST}
      CELERY_BROKER_PORT: ${ORCHESTRATOR_CELERY_BROKER_PORT}
      CELERY_BROKER_PROTOCOL: ${ORCHESTRATOR_CELERY_BROKER_PROTOCOL}
      CELERY_TASK_TIME_LIMIT: ${ORCHESTRATOR_CELERY_TASK_TIME_LIMIT}
      CELERY_SCHEDULE_REQUEST_ACTUAL_APP_LIST: ${ORCHESTRATOR_CELERY_SCHEDULE_REQUEST_ACTUAL_APP_LIST}
      CELERY_SCHEDULE_REQUEST_FOR_APPS_DATA: ${ORCHESTRATOR_CELERY_SCHEDULE_REQUEST_FOR_APPS_DATA}

      DB_USER: ${ORCHESTRATOR_DB_USER}
      DB_PASSWORD: ${ORCHESTRATOR_DB_PASSWORD}
      DB_HOST: ${ORCHESTRATOR_DB_HOST}
      DB_PORT: ${ORCHESTRATOR_DB_PORT}
      DB_NAME: ${ORCHESTRATOR_DB_NAME}
      DB_DRIVER: ${ORCHESTRATOR_DB_DRIVER}
      DB_TYPE: ${ORCHESTRATOR_DB_TYPE}
    depends_on:
      - orchestrator-worker-broker
      - orchestrator-db
      - orchestrator-task-broker
    networks:
      - common
      - orchestrator
    # TODO: expose. Now for debug
    ports:
      - "${ORCHESTRATOR_PORT:-8888}:8888"

  orchestrator-db:
    # TODO: configure resources consumption
    image: postgres:16
    restart: always
    environment:
      POSTGRES_USER: ${ORCHESTRATOR_DB_USER}
      POSTGRES_PASSWORD: ${ORCHESTRATOR_DB_PASSWORD}
      POSTGRES_DB: ${ORCHESTRATOR_DB_NAME}
    expose:
      - "${ORCHESTRATOR_DB_PORT:-5432}"
    volumes:
      - orchestrator-db-data:/var/lib/postgresql/data
    networks:
      - orchestrator

  orchestrator-task-broker:
    image: redis:latest
    expose:
      - "6379"
    networks:
      - orchestrator

  # worker #########################################################

  worker:
    build:
      context: /worker
    container_name: worker
    environment:
      DEBUG: ${DEBUG}
      DEFAULT_COUNTRY_CODE: ${DEFAULT_COUNTRY_CODE}
      OAUTH2_SERVER_HOST: ${OAUTH2_SERVER_HOST}
      OAUTH2_SERVER_PORT: ${OAUTH2_SERVER_PORT}
      OAUTH2_SERVER_PROTOCOL: ${OAUTH2_SERVER_PROTOCOL}
      ESSENTIAL_WORKER_CLIENT_ID: ${ESSENTIAL_WORKER_CLIENT_ID}
      ESSENTIAL_WORKER_CLIENT_SECRET: ${ESSENTIAL_WORKER_CLIENT_SECRET}

      LOGGER_WRITE_IN_FILE: ${WORKER_LOGGER_WRITE_IN_FILE}
      LOGGER_LOG_FILES_PATH: ${WORKER_LOGGER_LOG_FILES_PATH}

      STEAM_APP_LIST_URL: ${STEAM_APP_LIST_URL}
      STEAM_APP_DETAIL_URL: ${STEAM_APP_DETAIL_URL}

      BACKEND_PROTOCOL: ${BACKEND_PROTOCOL}
      BACKEND_HOST: ${BACKEND_HOST}
      BACKEND_PORT: ${BACKEND_PORT}
      BACKEND_API_VERSION: ${BACKEND_API_VERSION}

      RABBITMQ_HOST: ${RABBITMQ_HOST}
      RABBITMQ_PORT: ${RABBITMQ_PORT}
      RABBITMQ_USER: ${RABBITMQ_USER}
      RABBITMQ_PASSWORD: ${RABBITMQ_PASSWORD}
      RABBITMQ_INCOME_QUERY: ${WORKER_RABBITMQ_INCOME_QUERY}
      RABBITMQ_OUTCOME_QUERY: ${WORKER_RABBITMQ_OUTCOME_QUERY}
      RABBITMQ_CONNECTION_ATTEMPTS: ${RABBITMQ_CONNECTION_ATTEMPTS}
      RABBITMQ_CONNECTION_RETRY_DELAY: ${RABBITMQ_CONNECTION_RETRY_DELAY}
      RABBITMQ_HEARTBEATS_MAX_DELAY: ${RABBITMQ_HEARTBEATS_MAX_DELAY}

      CELERY_NAME: ${WORKER_CELERY_NAME}
      CELERY_BROKER_HOST: ${WORKER_CELERY_BROKER_HOST}
      CELERY_BROKER_PORT: ${WORKER_CELERY_BROKER_PORT}
      CELERY_BROKER_PROTOCOL: ${WORKER_CELERY_BROKER_PROTOCOL}
      CELERY_TASK_COMMON_RATE_LIMIT: ${WORKER_CELERY_TASK_COMMON_RATE_LIMIT}
      CELERY_TASK_TIME_LIMIT: ${WORKER_CELERY_TASK_TIME_LIMIT}
    depends_on:
      - orchestrator-worker-broker
      - worker-celery-broker
    networks:
      - common
      - worker

  worker-celery-broker:
    image: redis:alpine
    expose:
      - "6379"
    networks:
      - worker

  worker-celery-flower:
    # TODO: docker-compose.dev.yml
    image: mher/flower
    # TODO: build broker url
    command: celery --broker=redis://worker-celery-broker:6379/0 flower
    ports:
      - "5555:5555"
    depends_on:
      - worker-celery-broker
      - worker
    networks:
      - common
      - worker

  # logs ###########################################################

  log-shipper:
    image: docker.elastic.co/beats/filebeat:8.4.3
    command: filebeat -e --strict.perms=false
    user: root  # FIXME: insecure
    volumes:
      - ./logs/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro,Z
      - type: bind
        source: /var/lib/docker/containers
        target: /var/lib/docker/containers
        read_only: true
      - type: bind
        source: /var/run/docker.sock  # FIXME: insecure
        target: /var/run/docker.sock
        read_only: true
    environment:
      KAFKA_HOST: ${LOGS_KAFKA_HOST}
      KAFKA_PORT: ${LOGS_KAFKA_PORT}
    networks:
      - common

  log-queue:
    image: wurstmeister/kafka:latest
    volumes:
      - log-queue-data:/kafka
    environment:
      # for host connection as well
      # KAFKA_ADVERTISED_LISTENERS: INSIDE://kafka:9092,OUTSIDE://localhost:9094
      # KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      # KAFKA_LISTENERS: INSIDE://0.0.0.0:9092,OUTSIDE://0.0.0.0:9094
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://${LOGS_KAFKA_HOST}:${LOGS_KAFKA_PORT:-9092}
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT  # FIXME: insecure
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:${LOGS_KAFKA_PORT:-9092}
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_BROKER_ID: 1

      KAFKA_ZOOKEEPER_CONNECT: ${LOGS_ZOOKEEPER_HOST}:${LOGS_ZOOKEEPER_PORT:-2181}
      ZOOKEEPER_CONNECTION_TIMEOUT_MS: 18000

      NUM_PARTITIONS: 1
      DEFAULT_REPLICATION_FACTOR: 1
      LOG_RETENTION_HOURS: 168
      LOG_SEGMENT_BYTES: 536870912  # 512 MB
      LOG_RETENTION_CHECK_INTERVAL_MS: 300000

      NUM_NETWORK_THREADS: 3
      NUM_IO_THREADS: 8
      SOCKET_SEND_BUFFER_BYTES: 102400
      SOCKET_RECEIVE_BUFFER_BYTES: 102400
      SOCKET_REQUEST_MAX_BYTES: 104857600
      REQUEST_TIMEOUT_MS: 60000
      SESSION_TIMEOUT_MS: 60000

      DELETE_TOPIC_ENABLE: true
      AUTO_CREATE_TOPICS_ENABLE: true
    expose:
      - "${LOGS_KAFKA_PORT:-9092}"
      - "9094"
    networks:
      - common
    depends_on:
      - log-queue-coordinator

  log-queue-coordinator:
    image: wurstmeister/zookeeper:latest
    expose:
      - "${LOGS_ZOOKEEPER_PORT:-2181}"
    networks:
      - common

  log-stash:  # literally logstash lol
    image: logstash:8.4.3
    volumes:
      - ./logs/logstash/config.yml:/usr/share/logstash/config/logstash.yml:ro
      - ./logs/logstash/pipelines.yml:/usr/share/logstash/config/pipelines.yml:ro
      - ./logs/logstash/pipelines:/usr/share/logstash/config/pipelines:ro
    environment:
      LS_JAVA_OPTS: "-Xms${LOGS_LOGSTASH_MEMORY:-512m} -Xmx${LOGS_LOGSTASH_MEMORY:-512m}"
      KAFKA_HOST: ${LOGS_KAFKA_HOST}
      KAFKA_PORT: ${LOGS_KAFKA_PORT}
      ELASTICSEARCH_HOST: ${LOGS_ELASTICSEARCH_HOST}
      ELASTICSEARCH_PORT: ${LOGS_ELASTICSEARCH_PORT}
      ELASTICSEARCH_USER: ${LOGS_ELASTICSEARCH_USER}
      ELASTICSEARCH_PASSWORD: ${LOGS_ELASTICSEARCH_PASSWORD}
    expose:
      - "5000"
      - "9600"
    networks:
      - common
      - logs
    depends_on:
      - log-storage

  log-storage:
    image: elasticsearch:8.4.3
    volumes:
      - log-storage-data:/usr/share/elasticsearch/data
    environment:
      ES_JAVA_OPTS: "-Xms${LOGS_ELASTICSEARCH_MEMORY:-512m} -Xmx${LOGS_ELASTICSEARCH_MEMORY:-512m}"
      ELASTIC_USERNAME: ${LOGS_ELASTICSEARCH_USER}
      ELASTIC_PASSWORD: ${LOGS_ELASTICSEARCH_PASSWORD}
      xpack.security.enabled: false  # FIXME: insecure
      # TODO: xpack.security.http.ssl.certificate
      discovery.type: single-node
      cluster.name: logs
    networks:
      - logs
    expose:
      - "${LOGS_ELASTICSEARCH_PORT:-9200}"
      - "9300"

  log-storage-gui:
    image: kibana:8.4.3
    environment:
      ELASTICSEARCH_HOSTS: "http://${LOGS_ELASTICSEARCH_HOST:-log-storage}:${LOGS_ELASTICSEARCH_PORT:-9200}"
      ELASTICSEARCH_USERNAME: ${LOGS_ELASTICSEARCH_USER}
      ELASTICSEARCH_PASSWORD: ${LOGS_ELASTICSEARCH_PASSWORD}
    depends_on:
      - log-storage
    networks:
      - logs
    ports:
      - "5601:5601"

  # web-servers #######################################################################

  web:
    image: nginx:latest
    ports:
      - "80:80"
      - "5000:5000"
    environment:
      AUTH_HOST: ${OAUTH2_SERVER_HOST}
      AUTH_PORT: ${OAUTH2_SERVER_PORT}
      BACKEND_HOST: ${BACKEND_HOST}
      BACKEND_PORT: ${BACKEND_PORT}
    command:
      - /bin/bash
      - -c
      - |
        envsubst '$$AUTH_HOST $$AUTH_PORT'< /etc/nginx/conf.d/auth.conf.template > /etc/nginx/conf.d/auth.conf
        envsubst '$$BACKEND_HOST $$BACKEND_PORT' < /etc/nginx/conf.d/backend.conf.template > /etc/nginx/conf.d/backend.conf
        nginx -g 'daemon off;'
    volumes:
      - ./web/nginx/nginx.conf:/etc/nginx/nginx.conf
      - ./web/nginx/auth/auth.conf.template:/etc/nginx/conf.d/auth.conf.template
      - ./web/nginx/backend/backend.conf.template:/etc/nginx/conf.d/backend.conf.template
      - auth-static:/usr/share/nginx/html/static/auth/admin
    networks:
      - common
    depends_on:
      - backend
      - auth


volumes:
  # FIXME: "-" instead of "_"
  mongo_data:
  auth-db-data:
  auth-static:
  backend-db-data:
  ftsearch-index-data:
  ftsearch-etl-state-storage-data:
  orchestrator-db-data:
  orchestrator-worker-broker-data:
  log-storage-data:
  log-queue-data:

networks:
  common:
    driver: bridge
  auth:
    driver: bridge
  worker:
    driver: bridge
  orchestrator:
    driver: bridge
  backend:
    driver: bridge
  logs:
    driver: bridge
