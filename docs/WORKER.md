# Worker

Сервис-сборщик, взаимодействует со Steam API, получая данные о приложениях, которые отправляет в Backend API.
Получает задания на запрос данных от **Сервиса-Оркестратора**, отчитывается ему об успешно запрошенных и запушенных в бекенд приложениях.

## Стек:

- [Celery](https://docs.celeryq.dev/en/stable/) - фреймворк для асинхронного выполнения задач / асинхронная очередь задач
- [Redis](https://redis.io/) - брокер сообщений для Celery
- [Pika](https://pika.readthedocs.io/en/stable/) - биндинг RabbitMQ для взаимодействия с сервисом-оркестратором
- [Pydantic](https://pydantic-docs.helpmanual.io/) - дочерняя либа [pydantic-settings](https://pydantic-docs.helpmanual.io/usage/settings/) для работы с переменными окружения
- [Aiohttp](https://aiohttp.readthedocs.io/en/stable/) - асинхронные HTTP-запросы
- [Requests](https://requests.readthedocs.io/en/latest/) - синхронные HTTP-запросы

## Как устроен:

Worker состоит из **2** процессов:

## Основной процесс

Основной процесс бесконечно слушает очередь RabbitMQ, предназначенную для поступающих задач для worker'ов.
Задачи бывают **3** видов:
- > _Получи список id всех приложений в Steam_
- > _Получи данные об приложении c ID 1 в стране "A"_
- > _Получи данные об приложениях с ID [1, 2, 3] в странах ["A", "B", "C"]_

Обработкой полученных от RabbitMQ сообщений занимается сущность `TaskManager`. Она содержит алгоритмы решения каждой из задач, интерфейс для взаимодействия с RabbitMQ для отправки ответных задач и API-клиент для отправки запросов в Backend API.
Последовательность действия `TaskManager` при получении очередного сообщения из очереди RabbitMQ:
1. По содержимому сообщения определяется тип задачи
2. Выполняется соответствующий алгоритм решения задачи
   1. Для запросов к Steam API ставится Celery-задача (об этом далее)
   2. Отправляет полученные данные в Backend API
   3. По завершению отправляется ответная задача оркестратору в RabbitMQ
3. Пришедшее RabbitMQ сообщение подтверждается, если задача успешно выполнилась, иначе отклоняется.

Ответное сообщение из пункта 2.3 для Задачи 1 содержит актуальный список ID всех приложений, а для Задач 2 и 3 список ID успешно обновленных приложений.

Backend API Клиент использует под капотом асинхронную Aiohttp-сессию с возможностью ее потокобезопасного шейринга между несколькими экземплярами клиента,
а также реализует механизм автоматической аутентификации на Auth-сервере. Он прилагает токен к запросам и обновляет, когда срок их действия истекает, абстрагируя пользователя клиента от этого.

Алгоритм задачи запроса сразу нескольких приложений работает в асинхронном event loop, используя для пуша в Backend не стандартный `asyncio.gather`, а динамический пулл `asyncio.Task`. То есть запросы-корутины не собираются в список, который должен быть передан `asyncio.gather` для конкурентного выполнения, а сразу оборачиваются в `asyncio.Task` и сохраняются в пулл с колбеком, который удаляет их из этого пула по завершению запроса.
Это позволяет не откладывать выполнение запросов к Backend до конца алгоритма, а выполнять их сразу, используя промежутки ожидания запросов к Steam.

## Конвейер запросов

Steam API имеет ограничение: **не более 40 запросов в минуту**.

Чтобы не попасть в бан, необходимо гарантировать соблюдение этого лимита.
Использование для этого таймаутов внутри кода является крайне ненадежным и плохо конфигурируемым решением. И такое решение становится полностью нерабочим, если понадобится, чтобы Worker мог обрабатывать более 1 задачи единовременно.

Сейчас Worker работает в блокирующем режиме, не принимая новые задачи, пока выполняется текущая. (Из-за того, что поток выполнения блокируется, приходится заводить дополнительный поток, который в фоне отправляет heartbeat-сигналы в RabbitMQ).
Однако это довольно легко исправить - обрабатывать задачи в отдельных потоках (контролируя их количество).

Чтобы гарантировать, что N независимых потоков (хотя сейчас N=1) не превысят лимит запросов, эти потоки используют общий _**конвейер запросов**_ основанный на Celery.

> **Идея проста**: когда нужно выполнить запрос к Steam API, не делать это напрямую, а поставить Celery-задачу. Так как Celery App общий для всех N потоков, то установка ограничения на кол-во выполняемых задач в самом Celery гарантирует, что этот лимит будет разделен между всеми потоками, и они вместе не превысят лимит запросов. Celery работает в отдельном процессе, что делает конвейер независимым от ошибок в основном процессе.

Не обошлось без костылей: так как требуется получить результаты выполнения Celery-задачи в том же месте, в каком она была вызвана, а весь код выполняется асинхронно, то такое ожидание намертво заблокирует поток.
Для этого над задачами используется примитивная async-обертка, которая бесконечно опрашивает Celery-задачу на предмет ее готовности, выполняя неблокирующие `async.sleep` в перерывах между запросами, давая время другим корутинам в event loop.

## TODO

- [x] ~~**Type Hints:** Добавить аннотацию типов там, где она отсутствует~~
- [ ] **Поддержка Proxy:** из-за ограничения кол-ва запросов к Steam API, не имеет смысла заводить более 1 Worker'a на хосте, т.к. они будут разделять общий IP
- [ ] **Proxy Pool:** Модификация конвейера задач, позволяющая использовать >1 прокси в рамках одного Worker'a: при выполнении запроса из пулла забирается прокси и блокируется на время выполнения запроса + таймаут, чтобы избежать блокировки. После прокси возвращается в пулл.
- [ ] **Параллельное выполнение задач:** Обработка поступающих задач в отдельных потоках (не забыть про ограничение кол-ва потоков).
- [ ] **Отделить интерфейс Pika от TaskManager:** Абстрагировать `TaskManager` от конкретной реализации канала сообщений (в данном случае pika) (Dependency Inversion).
- [ ] **FIXME: Баг в обработке Batch-задачи:** Алгоритм помечает приложение как успешно полученное, если не все страны были успешно запрошены.