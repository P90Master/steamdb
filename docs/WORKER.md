# Worker

Сервис-сборщик, взаимодействует со Steam API, получая данные о приложениях, которые отправляет в Backend API.
Получает задания на запрос данных от **Сервиса-Оркестратора**, отчитывается ему об успешно запрошенных и запушенных в бекенд приложениях.

## Стек:

- [Celery](https://docs.celeryq.dev/en/stable/) - фреймворк для асинхронного выполнения задач / асинхронная очередь задач
- [Flower](https://flower.readthedocs.io/en/latest/) - визуальный мониторинг Celery-задач
- [Redis](https://redis.io/) - брокер сообщений для Celery
- [Pika](https://pika.readthedocs.io/en/stable/) - биндинг [RabbitMQ](https://www.rabbitmq.com/) для взаимодействия с сервисом-оркестратором
- [Pydantic](https://pydantic-docs.helpmanual.io/) - дочерняя либа [pydantic-settings](https://pydantic-docs.helpmanual.io/usage/settings/) для работы с переменными окружения
- [Aiohttp](https://aiohttp.readthedocs.io/en/stable/) - асинхронные HTTP-запросы
- [Requests](https://requests.readthedocs.io/en/latest/) - синхронные HTTP-запросы

## Как устроен:

Worker состоит из **2** процессов:

## Основной процесс

Основной процесс бесконечно слушает очередь RabbitMQ, предназначенную для поступающих задач для worker'ов.
Задачи бывают **3** видов:
- > _Получи список id всех приложений в Steam_
- > _Получи данные об приложении c ID 1 в стране "A"_
- > _Получи данные об приложениях с ID [1, 2, 3] в странах ["A", "B", "C"]_

Обработкой полученных от RabbitMQ сообщений занимается сущность `TaskManager` (см. [код](https://github.com/P90Master/steamdb/blob/main/worker/worker/messenger/tasks.py#L37)). Он содержит алгоритмы решения каждой из задач, интерфейс для взаимодействия с RabbitMQ для отправки ответных задач и API-клиент для отправки запросов в Backend API.

Получая очередное сообщение, `TaskManager` узнает тип задачи и передает его нужному хендлеру, отправляя ack по завершению.
Хендлер может регистрировать задачи для оркестратора: обновив данные о приложении на бекенде, воркер отправит сообщение оркестратору, чтобы тот обновил статус приложения в своей базе (см [Оркестратор](ORCHESTRATOR.md#основной-процесс)).

**Backend API Клиент** использует под капотом асинхронную Aiohttp-сессию с возможностью ее потокобезопасного шейринга между несколькими экземплярами клиента и реализует механизм автоматической аутентификации на Auth-сервере. Он прилагает токен к запросам и обновляет, когда срок их действия истекает, абстрагируя пользователя клиента от этого. (см. [код](https://github.com/P90Master/steamdb/blob/main/worker/worker/api/base.py#L179))

Bulk-обновление приложений работает в асинхронном event loop, используя для пуша в Backend не стандартный `asyncio.gather`, а динамический пулл `asyncio.Task`.
Запросы-корутины не собираются в список, который должен быть передан `asyncio.gather` для конкурентного выполнения, а сразу оборачиваются в `asyncio.Task` и сохраняются в пулл с колбеком, который удаляет их из этого пула по завершению запроса.
Это позволяет не откладывать выполнение запросов к Backend до конца алгоритма, а выполнять их сразу, используя промежутки ожидания запросов к Steam. (см. [код](https://github.com/P90Master/steamdb/blob/main/worker/worker/messenger/tasks.py#L214)

## Конвейер запросов

Steam API имеет ограничение: **не более 40 запросов в минуту**.

Чтобы не попасть в бан, необходимо гарантировать соблюдение этого лимита.
Использование для этого таймаутов внутри кода является крайне ненадежным и плохо конфигурируемым решением. И такое решение становится полностью нерабочим, если понадобится, чтобы Worker мог обрабатывать более 1 задачи единовременно.

Сейчас Worker работает в блокирующем режиме, не принимая новые задачи, пока выполняется текущая.
(Из-за того, что поток выполнения блокируется, приходится заводить дополнительный поток, который в фоне отправляет heartbeat-сигналы в RabbitMQ).
Однако это довольно легко исправить - надо обрабатывать задачи в отдельных потоках (либо наконец переехать на [SelectConnection](WORKER.md#TODO)).

Чтобы гарантировать, что N независимых потоков (хотя сейчас N=1) не превысят лимит запросов, эти потоки используют общий _**конвейер запросов**_ основанный на Celery.

> **Идея проста**: когда нужно выполнить запрос к Steam API, не делать это напрямую, а поставить Celery-задачу. Так как Celery App общий для всех N потоков, то установка ограничения на кол-во выполняемых задач в самом Celery гарантирует, что этот лимит будет разделен между всеми потоками, и они вместе не превысят лимит запросов. Celery работает в отдельном процессе, что делает конвейер независимым от ошибок в основном процессе.

Не обошлось без костылей: так как требуется получить результаты выполнения Celery-задачи в том же месте, в каком она была вызвана, а весь код выполняется асинхронно, то такое ожидание намертво заблокирует поток.
Для этого над задачами используется примитивная async-обертка, которая бесконечно опрашивает Celery-задачу на предмет ее готовности, выполняя неблокирующие `async.sleep` в перерывах между запросами, давая время другим корутинам в event loop.

## Flower

В DEV-режиме на `WORKER_CELERY_FLOWER_PORT:-5555` порту поднимается сервис [Celery-Flower](https://flower.readthedocs.io/en/latest/) для визуального мониторинга celery-задач.

## TODO

- [x] ~~**Type Hints:** Добавить аннотацию типов там, где она отсутствует~~
- [ ] **Поддержка Proxy:** из-за ограничения кол-ва запросов к Steam API, не имеет смысла заводить более 1 Worker'a на хосте, т.к. они будут разделять общий IP
- [ ] **Proxy Pool:** Модификация конвейера задач, позволяющая использовать >1 прокси в рамках одного Worker'a: при выполнении запроса из пулла забирается прокси и блокируется на время выполнения запроса + таймаут, чтобы избежать блокировки. После прокси возвращается в пулл.
- [ ] **Параллельное выполнение задач:** Обработка поступающих задач в отдельных потоках (не забыть про ограничение кол-ва потоков).
- [ ] **Использовать SelectConnection в Pika:** Сейчас используется BlockingConnection, блокирующий поток выполнения.
- [ ] **Отделить интерфейс Pika от TaskManager:** Абстрагировать `TaskManager` от конкретной реализации канала сообщений (в данном случае pika) (Dependency Inversion).
- [ ] **FIXME: Баг в обработке Batch-задачи:** Алгоритм помечает приложение как успешно полученное, если не все страны были успешно запрошены.