# Logging System

Система по сбору, агрегации, хранению и отображению логов.

## Стек

- [Filebeat](https://www.elastic.co/products/beats/filebeat) - Сервис для сбора и передачи логов
- [Apache Kafka](https://kafka.apache.org/) - Брокер сообщений, хорошо работающий с потоковыми данными
- [Logstash](https://www.elastic.co/products/logstash) - Сервис для конвейерной обработки данных - в данном случае логов
- [Elasticsearch](https://www.elastic.co/) - Система поиска, удобная для хранения логов
- [Kibana](https://www.elastic.co/kibana/) - Платформа для визуализации данных, интегрируемая с Elasticsearch

## Как устроен:

Стандартный **ELK** стек, но с использованием Kafka между Filebeat-сборщиками и Logstash для повышения стабильности последнего.

**Filebeat** собирает логи с других контейнеров (о проблеме, которую этот подход порождает см. [Безопасность, а точнее ее отсутствие](#Безопасность)), проводит их первичное форматирование и пушит их в Kafka.

**Кластер Kafka** состоит из 1 ноды (не считая [Zookeeper](https://zookeeper.apache.org/)), имеет 1 общий топик на 1 партиции c 1 репликой.
Сообщения хранятся в Kafka не более недели.

**Logstash** работает с 1 пайплайном на 1 воркере, пуллит логи из общего топика Kafka, проводит их окончательную очистку от метаданных Filebeat и пушит их в Elasticsearch, в текущий активный индекс группы индексов `logs-*`, контролируемых ILM (см. [Ротация логов](#Ротация логов)).

**Kibana** будет доступна извне на 5601 порту. При первом запуске нужно создать Data View, указав паттерн `logs` - этот Data View будет выводить логи со всех компонентов в одну кучу:

<p align="center">
  <img src="https://github.com/P90Master/steamdb/blob/main/docs/img/logs_gui.png" alt="Logs GUI">
</p>

## Безопасность, а точнее ее отсутствие

В SingleNode-варианте деплоя (дефолтный) сбором логов со всех компонентов занимается один инстанс Filebeat.
Это порождает огромную дыру в безопасности, т.к. для сбора логов с других контейнеров ему монтируется докеровский сокет,
т.е. он получает прямой доступ к другим контейнерам, не говоря уже о том, что сам процесс Filebeat сидит из-под рута.

Для простоты базового деплоя Elasticsearch работает с `xpack.security.enabled: false` и без авторизации. Это также необходимо учитывать (нужно разжиться не self-signed сертификатами, ну либо добавить их в `http_ca.crt`) (это касается и всех взаимодействий по HTTP вместо HTTPS).

Считаем, что в проде у каждого компонента будет свой Filebeat

## Ротация логов

Ротация логов осуществляется с помощью [Index Lifecycle Management](https://www.elastic.co/guide/en/elasticsearch/reference/current/ilm.html).

Жизненный цикл индекса логов:

1. Создается автоматически ILM при попытке записать новые данные по элиасу индекс-группы `logs-*`, при отсутствии hot-индексов (активных).
2. Индекс находится в Hot (активной) стадии, в него записываются все последующие сообщения.
3. По достижении индексом возраста в 7 дней или превышении объема в 5ГБ происходит rollover - индекс переходит в стадию Delete, создается новый hot-индекс.
4. Индекс находится в Delete 30 дней, после чего удаляется.

## TODO:

- [ ] **Создать отдельные топики для каждого компонента в Kafka:** Для чистоты структуры, для каждого топика можно будет завести отдельный Logstash-пайплайн с возможностью уникальной обработки.
- [ ] **Увеличить количество партиций в топике(ах):** Для масштабирования. Можно еще пару нод в кластер добавить. **Важно:** партиции можно создавать, но не удалять (без удаления всего топика) + помнить об `auto.offset.reset=earliest` в консьюмерах, чтобы не потерять данные.
- [ ] **Добавить Worker'ов Logstash:** Если увеличить количество партиций, то добавить лишних консьюмеров для отказоустойчивости не помешает.
